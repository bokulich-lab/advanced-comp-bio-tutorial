{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bokulich-lab/sysbio_course_2022/blob/main/amplicon_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQRlv0ypvthh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ü¶† Amplicon Sequencing Data Analysis with Qiime 2\n",
    "This notebook, and the corresponding setup script were adapted from the [ISB Virtual Microbiome Series workshop](https://github.com/Gibbons-Lab/isb_course_2021) by Gibbons Lab (including all images, which are re-used with CC-BY-SA 4.0 license). The adapted materials accompany the **Advanced Block Course: Computational Biology**. This notebook gives a minimal example of 16S rRNA gene amplicon sequence analysis for bacterial community profiling with the bioinformatics platform [QIIME 2](https://qiime2.org/). To learn more about the QIIME 2 project, and applications in microbiome research and beyond, visit https://qiime2.org/.\n",
    "\n",
    "Save your own local copy of this notebook by using `File > Save a copy in Drive`. At some point you may be prompted to trust the notebook. We promise that it is safe ü§û\n",
    "\n",
    "**Disclaimer:**\n",
    "\n",
    "The Google Colab notebook environment will interpret any command as Python code by default. If we want to run bash commands we will have to prefix them by `!`. So any command you see with a leading `!` is a bash command and if you wanted to run it in your terminal you would omit the leading `!`. For example, if in the Colab notebook you ran `!wget` you would just run `wget` in your terminal. \n",
    "\n",
    "In this notebook we use the `!` prefix because we run all QIIME 2 commands using the [`q2cli`](https://github.com/qiime2/q2cli/) (QIIME 2 command-line interface). However, QIIME 2 also has a python API and a Galaxy interface. You can learn more about these and other QIIME 2 interfaces at https://qiime2.org/.\n",
    "\n",
    "## ‚ùóSTOP! Before you run this notebook... ‚ùó\n",
    "_Note:_ In order to fetch the sequencing data from NCBI, we need to provide our e-mail address. Please fill out your e-mail address below\n",
    "so that it can be used when connecting to the NCBI servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_email = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have entered in your email address, you can run the entire notebook by selecting `Runtime > Run all` from the menu in Google Colab. Some steps are time-comsuming and the entire notebook may take up to 30-60 minutes, so run the entire notebook now and we will inspect the commands and results as we work through as a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQRlv0ypvthh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "QIIME 2 is usually installed by following the [official installation instructions](https://docs.qiime2.org/2022.2/install/). However, because we are using Google Colab and there are some caveats to using conda here, we will have to hack around the installation a little. But no worries, we provide a setup script below which does all this work for us. üòå\n",
    "\n",
    "So...let's start by pulling a local copy of the project repository down from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFsZdvOuvZmq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/bokulich-lab/sysbio_course_2022.git materials\n",
    "!mkdir /content/prefetch_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eenIEY76mcv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will switch to working within the `materials` directory for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3NALJ7u6mBP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQVnDjFauZ-n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to set up our environment. This will take about 10 minutes.\n",
    "\n",
    "**Note**: This setup is only relevant for Google Colaboratory and will not work on your local machine. Please follow the [official installation instructions](https://docs.qiime2.org/2021.8/install/) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAyTazMCvrpf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run setup_qiime2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will use some python packages below, so let's load those here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's dataset\n",
    "\n",
    "Today we will use a small subset of public data from the [Earth Microbiome Project](https://www.nature.com/articles/nature24621), which profiled the microbiome of > 27,000 samples from different ecosystems across planet Earth. That study sought to explain generalizable rules to explain the diversity and biogeography of microbial life across the planet... in today's tutorial we will tackle a much more humble goal: quantitatively comparing the bacterial diversity of a small selection of earth's samples.\n",
    "\n",
    "We can use pandas to inspect some of the metadata about our samples, to learn more about what we are investigating today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>read_length</th>\n",
       "      <th>barcode</th>\n",
       "      <th>num_bases</th>\n",
       "      <th>bioproject</th>\n",
       "      <th>source</th>\n",
       "      <th>animal</th>\n",
       "      <th>saline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERR1548680</th>\n",
       "      <td>qiita_sid_1064:1064.G.CV263</td>\n",
       "      <td>151</td>\n",
       "      <td>ACAGGAGGGTGT</td>\n",
       "      <td>5456838</td>\n",
       "      <td>PRJEB14927</td>\n",
       "      <td>honey bee microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1548733</th>\n",
       "      <td>qiita_sid_1064:1064.G.CV328</td>\n",
       "      <td>151</td>\n",
       "      <td>AACCATGCCAAC</td>\n",
       "      <td>5436000</td>\n",
       "      <td>PRJEB14927</td>\n",
       "      <td>honey bee microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1548821</th>\n",
       "      <td>qiita_sid_1064:1064.H.CV214</td>\n",
       "      <td>151</td>\n",
       "      <td>GAGGTTCTTGAC</td>\n",
       "      <td>5223090</td>\n",
       "      <td>PRJEB14927</td>\n",
       "      <td>honey bee microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1529655</th>\n",
       "      <td>qiita_sid_1481:1481.PO1.2.T0</td>\n",
       "      <td>151</td>\n",
       "      <td>TCTAACGAGTGC</td>\n",
       "      <td>3804898</td>\n",
       "      <td>PRJEB14782</td>\n",
       "      <td>human microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1529656</th>\n",
       "      <td>qiita_sid_1481:1481.PO1.2.T8</td>\n",
       "      <td>151</td>\n",
       "      <td>CATCTGGGCAAT</td>\n",
       "      <td>3286364</td>\n",
       "      <td>PRJEB14782</td>\n",
       "      <td>human microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1529685</th>\n",
       "      <td>qiita_sid_1481:1481.PO5.10.T4</td>\n",
       "      <td>151</td>\n",
       "      <td>GCTTCCAGACAA</td>\n",
       "      <td>3030570</td>\n",
       "      <td>PRJEB14782</td>\n",
       "      <td>human microbiome</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1530728</th>\n",
       "      <td>qiita_sid_1222:1222.B1.5.11.06</td>\n",
       "      <td>141</td>\n",
       "      <td>GACGCACTAACT</td>\n",
       "      <td>27746200</td>\n",
       "      <td>PRJEB14793</td>\n",
       "      <td>ocean</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1530761</th>\n",
       "      <td>qiita_sid_1222:1222.B3.5.19.06</td>\n",
       "      <td>142</td>\n",
       "      <td>GAGCGTATCCAT</td>\n",
       "      <td>20439520</td>\n",
       "      <td>PRJEB14793</td>\n",
       "      <td>ocean</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1530769</th>\n",
       "      <td>qiita_sid_1222:1222.B4.5.9.06</td>\n",
       "      <td>142</td>\n",
       "      <td>TCACGGTGACAT</td>\n",
       "      <td>21630381</td>\n",
       "      <td>PRJEB14793</td>\n",
       "      <td>ocean</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1844439</th>\n",
       "      <td>qiita_sid_1714:1714.McG.PB02</td>\n",
       "      <td>150</td>\n",
       "      <td>TATGGAGCTAGT</td>\n",
       "      <td>6137796</td>\n",
       "      <td>PRJEB19497</td>\n",
       "      <td>soil</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1844440</th>\n",
       "      <td>qiita_sid_1714:1714.McG.PB1020</td>\n",
       "      <td>150</td>\n",
       "      <td>AACCATGCCAAC</td>\n",
       "      <td>6467126</td>\n",
       "      <td>PRJEB19497</td>\n",
       "      <td>soil</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1844443</th>\n",
       "      <td>qiita_sid_1714:1714.McG.PC210</td>\n",
       "      <td>150</td>\n",
       "      <td>ACTACCTCTTCA</td>\n",
       "      <td>5544241</td>\n",
       "      <td>PRJEB19497</td>\n",
       "      <td>soil</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1638444</th>\n",
       "      <td>qiita_sid_861:861.X10.jul09</td>\n",
       "      <td>149</td>\n",
       "      <td>TTCTGGTCTTGT</td>\n",
       "      <td>9809757</td>\n",
       "      <td>PRJEB15445</td>\n",
       "      <td>cenote</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1638445</th>\n",
       "      <td>qiita_sid_861:861.X10.mar09</td>\n",
       "      <td>149</td>\n",
       "      <td>GTTACAGTTGGC</td>\n",
       "      <td>17596411</td>\n",
       "      <td>PRJEB15445</td>\n",
       "      <td>cenote</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR1638446</th>\n",
       "      <td>qiita_sid_861:861.X52.jul09</td>\n",
       "      <td>149</td>\n",
       "      <td>GTCCACTTGGAC</td>\n",
       "      <td>11577867</td>\n",
       "      <td>PRJEB15445</td>\n",
       "      <td>cenote</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     alias  read_length       barcode  \\\n",
       "id                                                                      \n",
       "ERR1548680     qiita_sid_1064:1064.G.CV263          151  ACAGGAGGGTGT   \n",
       "ERR1548733     qiita_sid_1064:1064.G.CV328          151  AACCATGCCAAC   \n",
       "ERR1548821     qiita_sid_1064:1064.H.CV214          151  GAGGTTCTTGAC   \n",
       "ERR1529655    qiita_sid_1481:1481.PO1.2.T0          151  TCTAACGAGTGC   \n",
       "ERR1529656    qiita_sid_1481:1481.PO1.2.T8          151  CATCTGGGCAAT   \n",
       "ERR1529685   qiita_sid_1481:1481.PO5.10.T4          151  GCTTCCAGACAA   \n",
       "ERR1530728  qiita_sid_1222:1222.B1.5.11.06          141  GACGCACTAACT   \n",
       "ERR1530761  qiita_sid_1222:1222.B3.5.19.06          142  GAGCGTATCCAT   \n",
       "ERR1530769   qiita_sid_1222:1222.B4.5.9.06          142  TCACGGTGACAT   \n",
       "ERR1844439    qiita_sid_1714:1714.McG.PB02          150  TATGGAGCTAGT   \n",
       "ERR1844440  qiita_sid_1714:1714.McG.PB1020          150  AACCATGCCAAC   \n",
       "ERR1844443   qiita_sid_1714:1714.McG.PC210          150  ACTACCTCTTCA   \n",
       "ERR1638444     qiita_sid_861:861.X10.jul09          149  TTCTGGTCTTGT   \n",
       "ERR1638445     qiita_sid_861:861.X10.mar09          149  GTTACAGTTGGC   \n",
       "ERR1638446     qiita_sid_861:861.X52.jul09          149  GTCCACTTGGAC   \n",
       "\n",
       "            num_bases  bioproject                source animal saline  \n",
       "id                                                                     \n",
       "ERR1548680    5456838  PRJEB14927  honey bee microbiome    yes     no  \n",
       "ERR1548733    5436000  PRJEB14927  honey bee microbiome    yes     no  \n",
       "ERR1548821    5223090  PRJEB14927  honey bee microbiome    yes     no  \n",
       "ERR1529655    3804898  PRJEB14782      human microbiome    yes     no  \n",
       "ERR1529656    3286364  PRJEB14782      human microbiome    yes     no  \n",
       "ERR1529685    3030570  PRJEB14782      human microbiome    yes     no  \n",
       "ERR1530728   27746200  PRJEB14793                 ocean     no    yes  \n",
       "ERR1530761   20439520  PRJEB14793                 ocean     no    yes  \n",
       "ERR1530769   21630381  PRJEB14793                 ocean     no    yes  \n",
       "ERR1844439    6137796  PRJEB19497                  soil     no     no  \n",
       "ERR1844440    6467126  PRJEB19497                  soil     no     no  \n",
       "ERR1844443    5544241  PRJEB19497                  soil     no     no  \n",
       "ERR1638444    9809757  PRJEB15445                cenote     no     no  \n",
       "ERR1638445   17596411  PRJEB15445                cenote     no     no  \n",
       "ERR1638446   11577867  PRJEB15445                cenote     no     no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = pd.read_csv('data/metadata.tsv', sep='\\t', index_col=0)\n",
    "md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGWsqUfq5oSi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Our first QIIME 2 command\n",
    "\n",
    "The following schematic gives an overview of today's workflow:\n",
    "\n",
    "![our workflow](https://github.com/Gibbons-Lab/isb_course_2021/raw/main/docs/16S/assets/steps.png)\n",
    "\n",
    "Before we begin, we first need to import our input data as a QIIME 2 [\"artifact\"](https://dev.qiime2.org/latest/glossary/).\n",
    "\n",
    "We can import the data with the `import` action from the tools. Here, we will import a list of SRA run IDs that\n",
    "we will later use to fetch the corresponding sequences. For that we have to tell\n",
    "QIIME 2 what *type of data* we are importing and what *type of artifact* we want.\n",
    "\n",
    "**QoL Tip:** QIIME 2 commands can get very long. To split them up over several lines we can use `\\` which means \"continue on the next line\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mGgUrRf5pyb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime tools import \\\n",
    "  --type 'NCBIAccessionIDs' \\\n",
    "  --input-path data/ids.tsv \\\n",
    "  --output-path ids.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fetching sequencing data from NCBI\n",
    "The data we will be analyzing today is already deposited in the Sequence Read Archive (SRA) maintained by NCBI. Given a list of accession IDs,\n",
    "we can use the [**q2-fondue**](https://github.com/bokulich-lab/q2-fondue plugin to fetch all those sequences. They will be automatically imported into a QIIME artifact that we can then\n",
    "directly use for the subsequent analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime fondue get-all \\\n",
    "    --i-accession-ids ids.qza \\\n",
    "    --p-email {your_email} \\\n",
    "    --p-n-jobs 2 \\\n",
    "    --o-metadata metadata.qza  \\\n",
    "    --o-single-reads sequences.qza \\\n",
    "    --o-paired-reads sequences-paired.qza \\\n",
    "    --o-failed-runs failed-runs.qza \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The action above should have fetched all the single-end sequences we need. Since we have quality information for the sequencing reads, let's also generate\n",
    "our first visualization to inspect sequence quality.\n",
    "\n",
    "---\n",
    "\n",
    "Qiime 2 commands can become pretty long. Here are some pointers to remember the\n",
    "structure of a command:\n",
    "\n",
    "```\n",
    "qiime plugin action --i-argument1 ... --o-argument2 ...\n",
    "```\n",
    "\n",
    "Argument types usually begin with a letter denoting their meaning:\n",
    "\n",
    "- `--i-...` = input files\n",
    "- `--o-...` = output files\n",
    "- `--p-...` = parameters\n",
    "- `--m-...` = metadata\n",
    "\n",
    "If you ever need help, just add the `--help` flag to a command to see the help documentation for that plugin or command inline (or check out the online documentation at https://docs.qiime2.org/).\n",
    "\n",
    "---\n",
    "\n",
    "In this case we will use the `summarize` action from the `demux` plugin with the previously generated artifact as input and output the resulting visualization to the `qualities.qzv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feGa41cEApGs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime demux summarize \\\n",
    "    --i-data sequences.qza \\\n",
    "    --o-visualization qualities.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2GenFy3C8gu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can view the plot by downloading the .qzv file and opening it using http://view.qiime2.org. To download the file click on the folder symbol to the left, open the `materials` folder, and choose download from the dot menu next to the `qualities.qzv` file. Note that the visualization that opens in your browser window has multiple tabs, allowing you to also view the citation and data provenance information associated with this output.\n",
    "\n",
    "ü§î What do you observe across the read? Where would you truncate the reads?\n",
    "\n",
    "Note that `q2-fondue` downloads sequences belonging to each sample requested from NCBI, as well as metadata associated with these samples. For most of this tutorial we will use a smaller sample metadata file provided as a text file alongside the tutorial (no downloading needed). The medata file downloaded by `q2-fondue` contains even more information about these samples! This might be interesting to use below when you get to the exercises. You can inspect the full sample metadata (and various other sample and feature metadata) as an interactive table using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime metadata tabulate \\\n",
    "    --m-input-file metadata.qza \\\n",
    "    --o-visualization metadata.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "os5MeRvLIq0v",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Denoising amplicon sequence variants\n",
    "\n",
    "Raw DNA sequencing reads (in this case from a Illumina sequence data) can contain various types of errors, e.g., base call error, chimeric reads, or other defects. To correct and remove these errors, we will use QIIME 2's plugin for [DADA2](https://benjjneb.github.io/dada2/) to perform the following quality control steps:\n",
    "\n",
    "1. filter and trim the reads (i.e., to remove low quality terminal segments)\n",
    "2. find the most likely set of unique sequences in the sample (ASVs)\n",
    "3. remove chimeras\n",
    "4. count the abundances of each ASV\n",
    "\n",
    "\n",
    "This step can take a long time to run, so let's start the process and use the time to\n",
    "understand what is happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdLSMp9-Dl-d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime dada2 denoise-single \\\n",
    "    --i-demultiplexed-seqs sequences.qza \\\n",
    "    --p-trunc-len 140 \\\n",
    "    --p-n-threads 2 \\\n",
    "    --output-dir dada2 --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFpQQ5GHdbzX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If this step takes too long or fails, you can also copy the results from the treasure chest. **However, don't run the next cell if the previous cell completed successfully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFrfo-uCdoRz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obscure magic that will only copy if the previous command failed\n",
    "![ -d dada2 ] || cp -r results/dada2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YzrovxVj7U_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, this step ran, but we should also make sure it kind of worked. One good way to tell if the identified ASVs are representative of the sample is to see how many reads were maintained throughout the pipeline. Here, the most common issues and solutions are:\n",
    "\n",
    "**A large fraction of reads is lost during \"merging\" (only relevant for paired-end data)**\n",
    "\n",
    "![read overlap](https://gibbons-lab.github.io/isb_course_2020/16S/assets/read_overlap.png)\n",
    "\n",
    "In order to merge ASVs DADA2 uses an overlap of 12 bases between forward and reverse reads by default. Thus, your reads must allow for sufficient overlap *after* trimming. So if your amplified region is 450bp long and you have 2x250bp reads and you trim the last 30 bases of each read, truncating the length to 220bp, the total length of covered sequence is 2x220 = 440 which is shorter than 450bp so there will be no overlap. To solve this issue trim less of the reads or adjust the `--p-min-overlap` parameters to something lower (but not too low).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Most of the reads are lost as chimeric**\n",
    "\n",
    "![read overlap](https://gibbons-lab.github.io/isb_course_2020/16S/assets/chimera.png)\n",
    "\n",
    "This is usually an experimental issue as chimeras are introduced during amplification. If you can adjust your PCR, try to run fewer cycles. Chimeras can also be introduced by incorrect merging. If your minimum overlap is too small, ASVs may be merged at incorrect positions. Possible fixes are to increase the `--p-min-overlap` parameter or run the analysis on the forward reads only (in our empirical observations, chimeras are more likely to be introduced in the joined reads). *However, losing between 5-25% of your reads to chimeras is normal and does not require any adjustments.*\n",
    "\n",
    "Our denoising stats are contained in an artifact. We can view this report as an interactive table by running the command `qiime metadata tabulate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_Tr3Ujcj61w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime metadata tabulate \\\n",
    "    --m-input-file dada2/denoising_stats.qza \\\n",
    "    --o-visualization dada2/denoising-stats.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o75g7DSO2tu5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "What proprotion of reads was retained throughout the entire pipeline? Look at the final number of used reads (non-chimeric). What do you observe when comparing those values between samples and how might that affect diversity metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0ZV3_sGQ20u",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phylogeny and diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEit8p7V9Ht9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building a tree\n",
    "\n",
    "We can build a phylogenetic tree for our sequences using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PVNlD0g9MsX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime phylogeny align-to-tree-mafft-fasttree \\\n",
    "    --i-sequences dada2/representative_sequences.qza \\\n",
    "    --output-dir tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lB8NI0IiJgk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can create a visualization for the tree using the [empress](https://github.com/biocore/empress) Qiime 2 plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSS_y3Kligrc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime empress tree-plot \\\n",
    "    --i-tree tree/rooted_tree.qza \\\n",
    "    --o-visualization tree/empress.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmxTRou99a_n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This looks tree-like but is not particularly informative as is because we have not yet passed it any annotation information. For now, the main utility of our tree will be in complementing our diversity analyses. It will tell us which ASVs are more or less related to one another, which will allow us to calculate different kinds of ecological diversity metrics that are _phylogenetically aware_ (i.e., incorporate evolutionary distances to measure the similarity between communities on the basic of genetic/evolutionary diversity, rather than unique hits alone).\n",
    "\n",
    "## Alpha and Beta Diversity\n",
    "\n",
    "![sample sources](https://github.com/Gibbons-Lab/isb_course_2021/raw/main/docs/16S/assets/sample_sources.png)\n",
    "\n",
    "One of our main goals will be to compare the microbial composition from different environments. Some very common comparisons performed in microbial ecology include the species richness (alpha diversity) and similarity between communities (beta diversity), each of which can be compared with various metrics. Qiime 2 has many options and actions for each of these; here we will use a \"run-all\" command for diversity analyses to perform some of the most routine diversity measurements. This will\n",
    "\n",
    "1. Subsample our feature table so that each sample has the same total number of reads (Why?) \n",
    "2. Calculate alpha and beta diversity measures using multiple metrics (Why multiple? What do these measure?)\n",
    "3. Visualize [PCoA](https://en.wikipedia.org/wiki/Multidimensional_scaling) projections (PCoA is one dimensionality reduction method available in QIIME 2, and is very widely used in microbial ecology; t-sne and umap are also available in the `q2-diversity` plugin used here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0js6xHuw-NqF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime diversity core-metrics-phylogenetic \\\n",
    "    --i-table dada2/table.qza \\\n",
    "    --i-phylogeny tree/rooted_tree.qza \\\n",
    "    --p-sampling-depth 10000 \\\n",
    "    --m-metadata-file data/metadata.tsv \\\n",
    "    --output-dir diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uZBNVX-y2L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Statistical analyses\n",
    "\n",
    "Let's first have a look at alpha diversity. This action runs a series of [Kruskal-Wallis](https://en.wikipedia.org/wiki/Kruskal‚ÄìWallis_one-way_analysis_of_variance) tests to see if the normalized alpha diversity ([Shannon entropy](https://en.wikipedia.org/wiki/Diversity_index#Shannon_index) in this example) is different between groups (null hypothesis: all group medians are equal).\n",
    "\n",
    "Can we see a difference in the per-sample diversity across environments? And between animal-asociated and free-living communities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnkeX6iY--g-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime diversity alpha-group-significance \\\n",
    "    --i-alpha-diversity diversity/shannon_vector.qza \\\n",
    "    --m-metadata-file data/metadata.tsv \\\n",
    "    --o-visualization diversity/alpha_groups.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngH5fUeDQMO0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's use beta diversity to see how different the samples are from one another. First download `diversity/weighted_unifrac_emperor.qzv` and `diversity/unweighted_unifrac_emperor.qzv` and take a look at each. Do samples separate based on the environment? Which metric does a \"better job\" of separating these?\n",
    "\n",
    "We can check whether that separation is 'significant' by using a [PERMANOVA](https://en.wikipedia.org/wiki/Permutational_analysis_of_variance) test (null hypothesis: group centroids and dispersions are equivalent for all groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzNW92riQguX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime diversity adonis \\\n",
    "    --i-distance-matrix diversity/weighted_unifrac_distance_matrix.qza \\\n",
    "    --m-metadata-file data/metadata.tsv \\\n",
    "    --p-formula \"source\" \\\n",
    "    --p-n-jobs 2 \\\n",
    "    --o-visualization diversity/permanova.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB7WYPZ1DEoR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Taxonomy\n",
    "\n",
    "Another common question in microbial ecology research is to ask \"who is there\"? We have a set of sequences derived from our samples, and the next step is to classify these to predict the nearest taxonomic lineage (e.g., to detect known pathogens or other functionally important species). There are many approaches, some based on DNA sequence alignment and others based on machine learning models (e.g., using subsequence signatures).\n",
    "\n",
    "Here we will use a [Na√Øve Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) trained on k-mer frequencies derived from the GreenGenes 16S rRNA gene database. Various pre-trained classifiers can be downloaded from https://docs.qiime2.org/2022.2/data-resources/ (hint: use `q2View`'s provenance view to see how these were generated). We will use a \"bespoke\" classifer, which is trained using taxonomic class weights derived from the average frequency distributions of various microbial species across planet earth (using data from [Qiita](https://qiita.ucsd.edu/)). Use of taxonomic weights [improves classification accuracy](https://www.nature.com/articles/s41467-019-12669-6) vs. assuming uniform distributions, as it helps differentiate related species based on niche segregation patterns.\n",
    "\n",
    "Microbial taxonomy is a thorny topic that we don't have time to brush on now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drgYtfLbDosv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://data.qiime2.org/2022.2/common/gg-13-8-99-515-806-nb-weighted-classifier.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime feature-classifier classify-sklearn \\\n",
    "    --i-reads dada2/representative_sequences.qza \\\n",
    "    --i-classifier gg-13-8-99-515-806-nb-weighted-classifier.qza \\\n",
    "    --p-n-jobs 2 \\\n",
    "    --o-classification taxa.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xISxzBo6Mpka",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There are a few ways to view and evaluate taxonomic classifications using QIIME 2. We will qualitatively compare for now by inspecting the relative abundances of the different bacterial taxa we have in each sample using interactive barplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VTL2yEBMqfO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime taxa barplot \\\n",
    "    --i-table dada2/table.qza \\\n",
    "    --i-taxonomy taxa.qza \\\n",
    "    --m-metadata-file data/metadata.tsv \\\n",
    "    --o-visualization taxa_barplot.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_FVM8VfX_yQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also collapse data on a particular taxonomic rank using the QIIME 2 [q2-taxa plugin](https://docs.qiime2.org/2022.2/plugins/available/taxa/). Why might we want to look at different taxonomic ranks, rather than just looking at ASVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl72G8KaYmBm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime taxa collapse \\\n",
    "    --i-table dada2/table.qza \\\n",
    "    --i-taxonomy taxa.qza \\\n",
    "    --p-level 6 \\\n",
    "    --o-collapsed-table genus.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlVdzgfbZcjt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can export the table and convert it to a .csv file so that we can analyze these data using tools outside of the QIIME 2 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsxKf3yAZiHk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime tools export \\\n",
    "    --input-path genus.qza \\\n",
    "    --output-path exported\n",
    "!biom convert -i exported/feature-table.biom -o genus.tsv --to-tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TezGLSEGZrcn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now the data are in a common format and we can use them, for instance, to draw a heatmap using Pandas and Seaborn. Do not worry if you do not understand every bit of code here. This just serves to illustrate that you can get data out of QIIME 2 for custom visualizations (and this is even slicker when using QIIME 2's python API, as QIIME 2 objects can be \"viewed\" automatically as `DataFrames` or other python objects; but when using the CLI we just need to `export` the data first, as shown above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5zUjU8JZqL4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abundances = pd.read_table(\"genus.tsv\", skiprows=1, index_col=0)\n",
    "abundances.index = abundances.index.str.split(\";\").str[5]       # Use only the genus name\n",
    "abundances = abundances[~abundances.index.isin([\"g__\", \"__\"])]  # remove unclassified genera\n",
    "abundances = abundances.iloc[0:100]                             # use only the first 100 genera\n",
    "\n",
    "# Let's do a centered log-ratio transform: log x_i - log mean(x)\n",
    "transformed = abundances.apply(\n",
    "    lambda xs: np.log(xs + 0.5) - np.log(xs.mean() + 0.5),\n",
    "    axis=1)\n",
    "\n",
    "# and re-label the samples for the sake of plotting\n",
    "transformed.columns = [x + '_' + md.loc[x, 'source'] for x in transformed.columns]\n",
    "\n",
    "sns.clustermap(transformed.T, cmap=\"magma\", xticklabels=True, figsize=(19, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbRoCh1BR0GZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "Okay, that's enough time in the back seat. \n",
    "\n",
    "It's time to take the wheel üöó \n",
    "\n",
    "Now you can dive into the data üèä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Moq2YOvDSDap",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 1 - Supervised classification of microbiome data\n",
    "\n",
    "One pretty basic question we can ask is whether the microbial community composition is predictive of environmental type. \n",
    "Could you predict the source environment of a sample from 16S data alone? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1Q2ZpBEON42",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start with the `classify-samples-ncv` action and follow it up by finding and looking at the `heatmap` visualization afterwards that shows important taxa.\n",
    "\n",
    "We will try to build a machine learning model that can predict whether a microbiome is animal-associated or free-living. By default, this action will use a Random Forest classifier, but other algorithms can be selected with the `--p-estimator` parameter. This action will automaticall split your dataset into training and test sets (i.e., only a subset is used for model validation), but other actions in the `q2-sample-classifier` plugin allow other schemes (e.g., nested cross-validation).\n",
    "\n",
    "Also inspect the accuracy results to see how well the phenotype can be predicted from the microbial composition. Next, you could try predicting other sample metadata columns, different models, etc, to see what works best (why?)...\n",
    "\n",
    "I filled in the command for you but it is missing some inputs. Can you complete it? \n",
    "\n",
    "Try to use the genus table and not the ASV table here (why?).\n",
    "\n",
    "**QUESTIONS:**\n",
    "\n",
    "1) What does it mean for data to be in the 'training' or 'test' set? \n",
    "\n",
    "2) How well did this classifier perform? \n",
    "\n",
    "3) What ASVs contributed most to model performance? Why do you think these ASVs were so important?\n",
    "\n",
    "4) Do you think this is a model is broadly useful? Would it perform well on external data that it has not seen yet? Why or why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nhf1g2RpSCak",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf classifier\n",
    "!qiime sample-classifier classify-samples \\\n",
    "    --i-table [EMPTY] \\\n",
    "    --m-metadata-file data/metadata.tsv \\\n",
    "    --m-metadata-column source \\\n",
    "    --p-n-jobs 2 \\\n",
    "    --p-test-size 0.33 \\\n",
    "    --p-cv 1 \\\n",
    "    --output-dir classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy5HN4ZoS2-9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 2 - Decorate Your Tree üéÑ\n",
    "\n",
    "One visualization that we did not spend a lot of time on was the phylogentic tree of our ASVs. Let's change that! \n",
    "\n",
    "We previously viewed the tree before we had any annotations, and it was fairly boring. Now that we have taxonomy annotations and diversity data, let's decorate our tree. We will use the empress plugin again but this time with the `community-plot` option, which allows us to incorporate community and taxonomy information into our tree.\n",
    "\n",
    "Once again, I filled in the command but see if you can fill in the blanks...\n",
    "\n",
    "If you want to display this side-by-side with a PCoA plot, check out the `--i-pcoa` input.\n",
    "\n",
    "**QUESTIONS:**\n",
    "\n",
    "1) Are some of the branch lengths on the tree longer than you would expect? Do you notice anything interesting or suspicious about the taxonomic identities of these branches?\n",
    "\n",
    "2) Can you find examples of phyla that are polyphyletic (i.e. where clusters of ASVs from the same phylum are found in different locations on the tree, showing different commmon ancestors)? What about polyphyletic taxa at lower taxonomic levels, like at the family or genus levels? Why do you think these patterns exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tq9TWRMjkER5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!qiime empress community-plot \\\n",
    "    --i-tree [EMPTY] \\\n",
    "    --i-feature-table [EMPTY] \\\n",
    "    --m-sample-metadata-file [EMPTY] \\\n",
    "    --m-feature-metadata-file taxa.qza \\\n",
    "    --o-visualization community-tree-viz.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - create your own sequence reference database\n",
    "\n",
    "At the start of this workshop we used the q2-fondue plugin to download raw sequence data from NCBI Sequence Read Archive. A different plugin, RESCRIPt (https://github.com/bokulich-lab/RESCRIPt/) can be used to download gene or genome data from NCBI GenBank (and some other sources) to create a reference database (e.g., for taxonomic classification, sequence alignment, comparative genomics, et cetera), as well as various other functions for sequence database management.\n",
    "\n",
    "As a small exercise, here we will use RESCRIPt to generate a reference database of [NCBI RefSeqs](https://www.ncbi.nlm.nih.gov/refseq/targetedloci/16S_process/) 16S rRNA gene sequences. Then we demonstrate using [VSEARCH](https://pubmed.ncbi.nlm.nih.gov/27781170/) (via the q2-feature-classifier plugin) to align our query sequences against this reference database (in this case for the purpose of taxonomic classification, but other alignment tasks would also be possible here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime rescript get-ncbi-data \\\n",
    "  --p-query '33175[BioProject] OR 33317[BioProject]' \\\n",
    "  --o-sequences ncbi-refseqs.qza \\\n",
    "  --o-taxonomy ncbi-refseqs-taxonomy.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's your turn! Based on the outputs above, guess what should go where.\n",
    "# I have filled in various parameter settings but feel free to adjust these to\n",
    "# see how they work (or see the docs üòÄ)\n",
    "!qiime feature-classifier classify-consensus-vsearch \\\n",
    "  --i-query dada2/representative_sequences.qza \\\n",
    "  --i-reference-reads [EMPTY] \\\n",
    "  --i-reference-taxonomy [EMPTY] \\\n",
    "  --p-maxaccepts 3 \\\n",
    "  --p-maxhits 3 \\\n",
    "  --p-perc-identity 0.95 \\\n",
    "  --p-top-hits-only \\\n",
    "  --p-threads 2 \\\n",
    "  --p-min-consensus 0.51 \\\n",
    "  --o-classification taxa-vsearch.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally you should view the results as a barplot... you already did this above, so I will let you fill in the entire command! Make sure you use the correct filepath to use the vsearch taxonomic classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do the rest! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus exercise! Looking back\n",
    "\n",
    "One of the unique features of QIIME 2 is its integrated data provenance tracker, which embeds workflow information directly into output artifacts and visualizations. This makes QIIME 2-based workflows more transparent and reproducible, as this allows anyone to retrospectively review how any file was created (including relevant computational environment specs). We will now demonstrate a few ways to inspect and \"replay\" this provenance.\n",
    "\n",
    "Earlier in this workshop you may have used `q2View` to inspect provenance information. If you did not, try it now. Use https://view.qiime2.org/ to view the `community-tree-viz.qzv` that you just created in the exercise above. Click on the \"Provenance\" tab (top-right corner) to view the provenance graph, which displays the workflow steps used to create that output. You can also find citation information in the \"Details\" tab.\n",
    "\n",
    "`q2View` only allows inspection of one output at a time, however, and only supports retrospective provenance. A new QIIME 2 plugin, [provenance-lib](https://github.com/qiime2/provenance-lib) (still in alpha release at the time of writing) allows you to \"replay\" an entire workflow by collating all provenance information, (and/or) citation details, (and/or) and other information (e.g., metadata) into a single output. Here is an example to \"replay\" our workflow (but see `replay --help` to see other actions and options). This function parses all provenance data (and optionally metadata, citations, etc) in a directory of QIIME 2 outputs, and generates a workflow script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!replay provenance \\\n",
    "  --i-in-fp . \\\n",
    "  --p-recurse \\\n",
    "  --p-no-dump-recorded-metadata \\\n",
    "  --p-no-verbose \\\n",
    "  --o-out-fp ./q2-example-workflow-cli.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will display the script in-line to view the complete workflow (you can also download the file from Colab if you would prefer to view with a text viewer). There are many commands! Do you remember running all of these? \n",
    "\n",
    "If you have spotted some unusual entries, good work.¬†This replay script includes the provenance of some files that you downloaded (e.g., pre-trained classifiers) and this becomes enchained in the provenance of downstream results. You can use `q2View` to inspect the provenance of the pre-trained classifier (or the results of a downstream action that you ran) to see how those files were generated. Or you can use this replay script (with some modifications to update filepaths et cetera) to recreate these files yourself!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/materials/q2-example-workflow-cli.sh', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFuoGkWtptmR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "# ü¶† Space for inspiration\n",
    "\n",
    "If we make it this far, you can use this space to explore some other actions in QIIME 2, or export and analyze your data with other python functions (for example). As a starting place, check out all the QIIME 2 plugins already installed in your environment and see if anything sounds like an inspiring place to jump in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq919yDYqYoe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You can add more code cells with the \"+ Code\" button on the top right\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "amplicon_analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
